---
title: Estimating words' age of acquisition
author: "Mika Braginsky and Daniel Yurovsky"
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: tango
    theme: spacelab
---

```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE)
```

```{r, cache = FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(readr)
library(ggplot2)
library(langcog)
library(wordbankr)
library(boot)
library(lazyeval)
library(robustbase)
theme_set(theme_mikabr() +
            theme(panel.grid = element_blank(),
                  strip.background = element_blank()))
font <- "Open Sans"
```

Connect to the Wordbank database and pull out the raw data.
```{r, raw_data}
data_mode <- "local"

admins <- get_administration_data(mode = data_mode) %>%
  select(data_id, age, language, form)

items <- get_item_data(mode = data_mode) %>%
  mutate(num_item_id = as.numeric(substr(item_id, 6, nchar(item_id))),
         definition = tolower(definition))

languages <- c("Croatian", "Danish", "English", "French (Quebec)", "Italian",
               "Norwegian", "Russian", "Spanish", "Swedish", "Turkish")

words <- items %>%
  filter(type == "word", language %in% languages)

invalid_uni_lemmas <- words %>%
  group_by(uni_lemma) %>%
  filter(n() > 1,
         length(unique(lexical_class)) > 1) %>%
  select(language, uni_lemma, lexical_class, definition) %>%
  arrange(language, uni_lemma)

get_inst_data <- function(inst_items) {
  inst_language <- unique(inst_items$language)
  inst_form <- unique(inst_items$form)
  inst_admins <- filter(admins, language == inst_language, form == inst_form)
  get_instrument_data(instrument_language = inst_language,
                      instrument_form = inst_form,
                      items = inst_items$item_id,
                      administrations = inst_admins,
                      iteminfo = inst_items,
                      mode = data_mode) %>%
    filter(!is.na(age)) %>%
    mutate(produces = !is.na(value) & value == "produces",
           understands = !is.na(value) &
             (value == "understands" | value == "produces")) %>%
    select(-value) %>%
    gather(measure, value, produces, understands) %>%
    mutate(language = inst_language,
           form = inst_form)
}

get_lang_data <- function(lang_items) {
  lang_items %>%
    split(.$form) %>%
    map_df(get_inst_data) %>%
    # production for WS & WG, comprehension for WG only
    filter(measure == "produces" | form == "WG")
}

raw_data <- words %>%
  split(.$language) %>%
  map(get_lang_data)

#feather::write_feather(bind_rows(raw_data), "saved_data/raw_data.feather")
# raw_data <- feather::read_feather("saved_data/raw_data.feather") %>%
#   split(.$language)
```

Fit models to predict the proportion of children of each age who are reported to understands/produce each word, and the word's age of acquisition.
```{r, aoa_data}
fit_inst_measure_uni <- function(inst_measure_uni_data) {
  
  ages <- min(inst_measure_uni_data$age):max(inst_measure_uni_data$age)
  
  constants <- inst_measure_uni_data %>%
    ungroup() %>%
    select(language, measure, uni_lemma, lexical_class, words) %>%
    distinct() %>%
    group_by(language, measure, uni_lemma) %>%
    summarise(lexical_classes = lexical_class %>% unique() %>% sort() %>%
                paste(collapse = ", "),
              words = words %>% strsplit(", ") %>% unlist() %>% unique() %>%
                paste(collapse = ", "))

  props <- inst_measure_uni_data %>%
    ungroup() %>%
    select(age, prop)
  
  tryCatch({
    model <- robustbase::glmrob(cbind(num_true, num_false) ~ age,
                                family = "binomial",
                                data = inst_measure_uni_data, y = TRUE)
    fit <- predict(model, newdata = data.frame(age = ages), se.fit = TRUE)
    aoa <- -model$coefficients[["(Intercept)"]] / model$coefficients[["age"]]
    fit_prop <- inv.logit(fit$fit)
    fit_se <- fit$se.fit
  }, error = function(e) {
    aoa <<- fit <<- fit_prop <<- fit_se <<- NA
  })
  
  data_frame(age = ages, fit_prop = fit_prop, fit_se = fit_se,
             aoa = aoa, language = constants$language,
             measure = constants$measure,
             uni_lemma = constants$uni_lemma,
             lexical_classes = constants$lexical_classes,
             words = constants$words) %>%
    left_join(props, by = "age")
}

fit_inst_measure <- function(inst_measure_data) {
  inst_measure_by_uni <- inst_measure_data %>%
    group_by(language, measure, lexical_class, uni_lemma, definition, age, data_id) %>%
    summarise(uni_value = any(value),
              words = definition %>% sort() %>% paste(collapse = ", ")) %>%
    group_by(language, measure, lexical_class, uni_lemma, words, age) %>%
    summarise(num_true = sum(uni_value, na.rm = TRUE),
              num_false = n() - num_true,
              prop = mean(uni_value, na.rm = TRUE))
  inst_measure_by_uni %>%
    split(.$uni_lemma) %>%
    map_df(fit_inst_measure_uni)
}

fit_inst <- function(inst_data) {
  print(unique(inst_data$language))
  lang_uni_lemmas <- inst_data %>%
    select(uni_lemma, definition) %>%
    distinct() %>%
    filter(!is.na(uni_lemma))
  inst_data_mapped <- inst_data %>%
    select(-uni_lemma) %>%
    left_join(lang_uni_lemmas) %>%
    filter(!is.na(uni_lemma)) %>%
    group_by(definition) %>%
    filter("WG" %in% form)
  inst_data_mapped %>%
    split(.$measure) %>%
    map_df(fit_inst_measure)
}
```

```{r}
all_prop_data <- map_df(raw_data, fit_inst)
#feather::write_feather(all_prop_data, "saved_data/all_prop_data.feather")
```

Narrow down the data to each word's age of acquisition and filter these such that they are within specified ranges.
```{r}
aoa_data <- all_prop_data %>%
  select(language, measure, uni_lemma, lexical_classes, words, aoa) %>%
  distinct()

min_comp <- 0
max_comp <- 30
min_prod <- 0
max_prod <- 36
aoa_validation <- aoa_data %>%
  spread(measure, aoa) %>%
  mutate(present = !is.na(understands) & !is.na(produces),
         in_range = present &
           understands >= min_comp & understands <= max_comp &
           produces >= min_prod & produces <= max_prod,
         ordered = present & understands < produces) %>%
  group_by(language, present, in_range, ordered) %>%
  summarise(n = n())

aoa_data_filtered <- aoa_data %>%
  spread(measure, aoa) %>%
  filter(!is.na(understands) & !is.na(produces) &
           understands >= min_comp & understands <= max_comp &
           produces >= min_prod & produces <= max_prod) %>%
           # understands < produces
  gather(measure, aoa, understands, produces) %>%
  mutate(measure = factor(measure, levels = c("understands", "produces")))
  
feather::write_feather(aoa_data_filtered, "saved_data/aoa_data.feather")
```

```{r, fig.width=10, fig.height=8}
aoa_data_filtered %>%
  ggplot(aes(x = aoa, fill = measure)) +
  facet_wrap(~language) +
  geom_density(alpha = 0.5) +
  scale_fill_solarized(name = "") +
  xlab("Age of Acquisition (months)") +
  ylab("Density") +
  theme(legend.position = c(0.92, 0))
#ggsave("../reports/icis_talk/aoa_dist.png", width = 10, height = 7)
```

```{r}
# random_group <- function(n, probs) {
#   g <- findInterval(seq(0, 1, length = n), c(0, cumsum(probs)),
#                     rightmost.closed = TRUE)
#   names(probs)[sample(g)]
# }
# 
# split_raw_data <- raw_data %>%
#   map(function(inst_data) {
#     data_groups <- inst_data %>%
#       select(data_id) %>%
#       unique() %>%
#       mutate(group = random_group(n(), c("group1" = 0.5, "group2" = 0.5)))
#     inst_data %>%
#       left_join(data_groups) %>%
#       split(.$group)
#   }) %>%
#   transpose()
# 
# group_prop_data <- split_raw_data %>%
#   map(function(group_data) {
#     map_df(group_data, fit_inst)
#   })
# 
# joined_groups <- group_prop_data %>%
#   map2(names(group_prop_data), function(group_data, group_name) {
#     group_data %>%
#       select(language, lexical_category, uni_lemma, aoa) %>%
#       distinct() %>%
#       filter(aoa > 0 & aoa <= 30) #%>%
#     #mutate(group = group_name)
#   }) %>%
#   reduce(function(x, y) left_join(x, y, by = c("language", "lexical_category",
#                                                "uni_lemma"))) %>%
#   filter(!is.na(aoa.x), !is.na(aoa.y))
# 
# group_rsq <- joined_groups %>%
#   split(.$language) %>%
#   map(~lm(aoa.y ~ aoa.x, data = .)) %>%
#   map(summary) %>%
#   map_dbl("adj.r.squared")
# rsq_data <- data.frame(language = names(group_rsq),
#                        adj_rsq = group_rsq,
#                        row.names = NULL)
```

```{r}
# joined_groups %>%
#   mutate(lexical_category = factor(lexical_category,
#                                    levels = c("nouns", "predicates",
#                                               "function_words", "other"),
#                                    labels = c("Nouns", "Predicates",
#                                               "Function Words", "Other"))) %>%
#   ggplot(aes(x = aoa.x, y = aoa.y)) +
#   facet_wrap(~language, ncol = 4) +
#   geom_point(aes(colour = lexical_category), size = 0.8) +
#   geom_smooth(method = "lm", colour = "black") +
#   geom_text(aes(label = sprintf("rÂ² = %.2f", adj_rsq)),
#             data = rsq_data, x = 6, y = 29) +
#   scale_colour_solarized(name = "") +
#   theme(legend.position = "top")
```

```{r}
lag_models <- aoa_data_filtered %>%
  spread(measure, aoa) %>%
  group_by(language) %>%
  nest() %>%
  mutate(model = map(data, ~lm(produces ~ understands + lexical_class, data = .)),
         terms = map(model, tidy))

lag_fits <- lag_models %>%
  mutate(rsq = map(model, ~summary(.x)$adj.r.squared)) %>%
  select(language, rsq) %>%
  unnest()

lag_terms <- lag_models %>%
  select(-data, -model) %>%
  unnest() %>%
  select(language, term, estimate) %>%
  spread(term, estimate) %>%
  rename(intercept = `(Intercept)`, slope = understands)

plot_aoa <- aoa_data_filtered %>%
  spread(measure, aoa) %>%
  left_join(lag_terms) %>%
  mutate(predicted = intercept + slope * understands,
         error = abs(predicted - produces))
```

```{r}
ggplot(plot_aoa, aes(x = understands, y = produces)) +
  facet_wrap(~language) +
  coord_fixed() +
  geom_abline(aes(slope = 1, intercept = 0), linetype = "dashed",
              data = lag_terms, colour = "grey") +
  geom_abline(aes(slope = slope, intercept = intercept),
              data = lag_terms, colour = "grey") +
  geom_smooth(aes(colour = lexical_category), method = "lm", size = 0.6, se = FALSE) +
  geom_jitter(aes(colour = lexical_category), size = 0.5) +
  geom_text_repel(aes(label = uni_lemma, colour = lexical_class),
                  data = filter(plot_aoa, error > 10), size = 2, family = font,
                  force = 27, max.iter = 1e5) + 
  scale_colour_solarized() +
  scale_x_continuous(limits = c(0, 36)) +
  scale_y_continuous(limits = c(0, 36))
```
