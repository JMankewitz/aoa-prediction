---
title: Predicting Age of Acquisition for Early Words Across Languages
author: Mika Braginsky, Daniel Yurovsky, Virginia Marchman, and Michael C. Frank
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: tango
    theme: spacelab
---

```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE, fig.align = "center")
```

```{r, cache = FALSE, echo = FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(readr)
library(ggplot2)
library(langcog)
library(wordbankr)
library(boot)
library(lazyeval)
library(broom)
library(directlabels)
library(lme4)
theme_set(theme_mikabr())
```

Get items, words, and uni_lemmas.
```{r}
items <- get_item_data(mode = "local") %>%
  mutate(num_item_id = as.numeric(substr(item_id, 6, nchar(item_id))),
         definition = tolower(definition))

words <- items %>%
  filter(type == "word", !is.na(uni_lemma), form == "WG")

uni_lemmas <- words %>%
  #filter(language == "English") %>%
  select(lexical_category, uni_lemma) %>%
  distinct()
```

Get AoA estimates.
```{r aoa_data}
aoa_data <- read_csv("aoa_data.csv")
```

Get frequency estimates.
```{r}
instruments <- aoa_data %>%
  select(language, form) %>%
  distinct()

inst_freqs <- function(language, form) {
  freq_file <- sprintf("predictors/frequency/freqs/freqs_%s.csv", tolower(language))
  if (file.exists(freq_file)) {
    read_csv(freq_file) %>%
      rename(definition = item) %>%
      mutate(language = language, form = form,
             definition = tolower(definition))
  }
}

freqs <- map2(instruments$language, instruments$form, inst_freqs) %>%
  bind_rows() %>%
  right_join(words)
#  right_join(freq_words)

uni_freqs <- freqs %>%
  group_by(language, form, lexical_category, uni_lemma) %>%
  summarise(frequency = sum(frequency))

# ggplot(uni_freqs, aes(x = log(frequency))) +
#   facet_wrap(~language) +
#   geom_histogram()
```

Get MLU estimates.
```{r}
inst_mlu <- function(language, form) {
  mlu_file <- sprintf("predictors/frequency/mlus/mlus_%s.csv", tolower(language))
  if (file.exists(mlu_file)) {
    read_csv(mlu_file) %>%
      rename(definition = item) %>%
      mutate(language = language, form = form,
             definition = tolower(definition))
  }
}

mlus <- map2(instruments$language, instruments$form, inst_mlu) %>%
  bind_rows() %>%
  right_join(words)
#  right_join(freq_words)

uni_mlus <- mlus %>%
  group_by(language, form, lexical_category, uni_lemma) %>%
  summarise(mlu = mean(mlu)) %>%
  filter(mlu < 20) #TODO: do this better

# ggplot(uni_mlus, aes(x = mlu)) +
#   facet_wrap(~language) +
#   geom_histogram()
```

Get estimates of valence, arousal, and dominance
```{r}
valence <- read_csv("predictors/valence/valence.csv") %>%
  select(Word, V.Mean.Sum, A.Mean.Sum, D.Mean.Sum) %>%
  rename(word = Word, valence = V.Mean.Sum, arousal = A.Mean.Sum,
         dominance = D.Mean.Sum)

#missing_valence <- setdiff(uni_lemmas$uni_lemma, valence$word)
# write_csv(data.frame(uni_lemma = missing_babiness),
#           "predictors/valence/valence_replace.csv")

replacements_valence <- read_csv("predictors/valence/valence_replace.csv")
uni_valences <- uni_lemmas %>%
  left_join(replacements_valence) %>%
  rowwise() %>%
  mutate(word = if (!is.na(replacement) & replacement != "") replacement else uni_lemma) %>%
  select(-replacement) %>%
  left_join(valence) %>%
  select(-word)
  #select(-word, -lexical_class, -lexical_category)

#uni_valences <- read_csv("predictors/valence/uni_lemma_valence.csv")
```

Get estimates of iconicity and babiness.
```{r}
babiness <- read_csv("predictors/babiness_iconicity/english_iconicity.csv") %>%
  group_by(word) %>%
  summarise(iconicity = mean(rating),
            babiness = mean(babyAVG))

#missing_babiness <- setdiff(uni_lemmas$uni_lemma, babiness$word)
# write_csv(data.frame(uni_lemma = missing_babiness),
#           "predictors/babiness_iconicity/babiness_iconicity_replace.csv")

replacements_babiness <- read_csv("predictors/babiness_iconicity/babiness_iconicity_replace.csv")
uni_babiness <- uni_lemmas %>%
  left_join(replacements_babiness) %>%
  rowwise() %>%
  mutate(word = if (!is.na(replacement) & replacement != "") replacement else uni_lemma) %>%
  select(-replacement) %>%
  left_join(babiness) %>%
  select(-word)

#uni_babiness <- read_csv("predictors/babiness_iconicity/babiness_iconicity.csv") 
```

Get estimates of concreteness.
```{r}
concreteness <- read_csv("predictors/concreteness/concreteness.csv")

#missing_concreteness <- setdiff(uni_lemmas$uni_lemma, concreteness$Word)
# write_csv(data.frame(uni_lemma = missing_concreteness),
#           "predictors/concreteness/concreteness_replace.csv")

replacements_concreteness <- read_csv("predictors/concreteness/concreteness_replace.csv")
uni_concreteness <- uni_lemmas %>%
  left_join(replacements_concreteness) %>%
  rowwise() %>%
  mutate(Word = if (!is.na(replacement) & replacement != "") replacement else uni_lemma) %>%
  select(-replacement) %>%
  left_join(concreteness) %>%
  rename(concreteness = Conc.M) %>%
  select(uni_lemma, concreteness)
```

Get (English) phoneme and syllable counts.
```{r}
phonemes <- read_csv("predictors/phonemes/english_phonemes.csv") %>%
  mutate(num_syllables = unlist(map(strsplit(syllables, " "), length)),
         num_phonemes = nchar(gsub("[', ]", "", syllables))) %>%
  select(-phones, -syllables)
```

Put together data and predictors.
```{r}
uni_joined <- aoa_data %>%
  left_join(uni_freqs) %>%
  left_join(uni_mlus) %>%
  left_join(uni_valences) %>%
  left_join(uni_babiness) %>%
  left_join(uni_concreteness) %>%
  left_join(phonemes) %>%
  mutate(frequency = log(frequency)) %>%
  distinct()
```

Function to get number of characters from item definitions.
```{r}
num_characters <- function(words) {
  words %>%
    strsplit(", ") %>%
    map(function(word_set) {
      word_set %>%
        unlist() %>%
        strsplit(" [(].*[)]") %>%
        unlist() %>%
        strsplit("/") %>%
        unlist() %>%
        gsub("[*' ]", "", .) %>%
        nchar() %>%
        mean()
    }) %>%
    unlist()
}
```

*  *  *  *

Analysis 1: English
-------------------

```{r}
english_predictors <- c("frequency", "mlu", "concreteness", "num_characters",
                        "valence", "arousal", "babiness")
# "iconicity" "dominance" "num_syllables" "num_phonemes"

english_data_fun <- function(uni_joined, english_predictors, num_characters) {
  
  woof_concreteness <- unique(uni_joined$concreteness[uni_joined$uni_lemma == "woof woof"])
  mean_babiness <- mean(filter(uni_joined, language == "English")$babiness, na.rm = TRUE)
  mean_iconicity <- mean(filter(uni_joined, language == "English")$iconicity, na.rm = TRUE)
  mean_valence <- mean(filter(uni_joined, language == "English")$valence, na.rm = TRUE)
  mean_arousal <- mean(filter(uni_joined, language == "English")$arousal, na.rm = TRUE)

  english_data <- uni_joined %>%
    filter(language == "English", measure == "understands") %>%
    rowwise() %>%
    mutate(num_characters = num_characters(words),
           #valence = if (is.na(valence)) 5 else valence,
           #arousal = if (is.na(arousal)) 1 else arousal,
           valence = if (is.na(valence)) mean_valence else valence,
           arousal = if (is.na(arousal)) mean_arousal else arousal,
           concreteness = if (is.na(concreteness)) woof_concreteness else concreteness,
           babiness = if (is.na(babiness)) mean_babiness else babiness,
           iconicity = if (is.na(iconicity)) mean_iconicity else iconicity) %>%
    ungroup() %>%
    #  mutate(valence = abs(valence - 5)) %>%
    group_by(language, measure) %>%
    mutate_each_(funs(as.numeric(scale(.))), english_predictors)
  
  return(english_data)
}

english_data <- english_data_fun(uni_joined, english_predictors, num_characters)

english_na_lemmas <- english_data %>%
  select_(.dots = c("uni_lemma", english_predictors)) %>%
  gather(predictor, value, -uni_lemma) %>%
  filter(is.na(value)) %>%
  group_by(uni_lemma) %>%
  summarise(num_na = n(), na_preds = paste(predictor, collapse = ", "))
  
english_model_data_fun <- function(english_data, english_predictors) {
  
  english_model_data <- english_data %>%
    ungroup() %>%
    select_(.dots = c("language", "lexical_category", "uni_lemma", "aoa", english_predictors)) %>%
    filter(complete.cases(.)) %>%
    mutate(lexical_category = factor(lexical_category,
                                  levels = c("nouns", "predicates",
                                             "function_words", "other"),
                                  labels = c("Nouns", "Predicates",
                                             "Function Words", "Other")))
  return(english_model_data)
}

english_model_data <- english_model_data_fun(english_data, english_predictors)

english_model_fun <- function(english_model_data, english_predictors) {

  english_formula <- as.formula(
    sprintf("aoa ~ %s", paste(english_predictors, collapse = " + "))
  )
  
  english_model <- lm(english_formula, data = english_model_data, y = TRUE)
  return(english_model)
}

english_model <- english_model_fun(english_model_data, english_predictors)

english_predictions_fun <- function(english_model_data, english_model) {
  english_predictions <- english_model_data
  english_predictions$predicted_aoa <- english_model$fitted.values
  return(english_predictions)
}

english_cor <- function(english_predictions) {
  cor(english_predictions$aoa, english_predictions$predicted_aoa)
}
  
english_predictions <- english_predictions_fun(english_model_data, english_model)

english_coef <- tidy(english_model) %>%
  filter(term != "(Intercept)")

english_predictors_ordered <- english_predictors %>%
  factor(levels = english_coef$term[order(abs(english_coef$estimate))])

english_predictor_levels <- english_coef$term[order(abs(english_coef$estimate),
                                                    decreasing = TRUE)]
english_coef <- english_coef %>%
  mutate(term = factor(term, levels = english_predictor_levels))
```

```{r, fig.width = 7, fig.height = 7}
# ggplot(english_predictions, aes(x = predicted_aoa, y = aoa)) +
#   geom_text(aes(label = uni_lemma, colour = lexical_class), cex = 4, show_guide = FALSE) +
#   geom_smooth(aes(colour = lexical_class), weight = 1, method = "lm", se = FALSE) +
#   geom_smooth(colour = "black", weight = 2, method = "lm") +
#   scale_colour_solarized(name = "") +
#   scale_x_continuous(name = "\nModel Predicted Age of Acquisition (months)",
#                      limits = c(6, 27), breaks = seq(6, 26, by = 2)) +
#   scale_y_continuous(name = "Age of Acquisition (months)\n",
#                      limits = c(6, 27), breaks = seq(6, 26, by = 2)) +
#   coord_fixed() +
#   theme(panel.grid.minor = element_blank(),
#         legend.position = c(0.12, 0.9),
#         legend.background = element_rect(fill = "transparent"))
```

```{r, fig.width = 12, fig.height = 8}
english_plot_data <- english_data %>%
  gather_("predictor", "value", english_predictors) %>%
  mutate(predictor = factor(predictor, levels = english_predictor_levels),
         lexical_class = factor(lexical_class,
                                levels = c("nouns", "adjectives", "verbs",
                                           "function_words", "other"),
                                labels = c("Nouns", "Adjectives", "Verbs",
                                           "Function Words", "Other")))

ggplot(english_plot_data, aes(x = value, y = aoa, colour = lexical_class)) +
  facet_grid(lexical_class ~ predictor) +
  geom_point(cex = 0.7) +
  geom_smooth(method = "lm", se = FALSE, cex = 1) +
  scale_colour_solarized(name = "") +
  xlab("\nPredictor Z-Score") +
  ylab("Age of Acquisition (months)\n") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal")
```

```{r, fig.width = 5, fig.height = 4}
# ggplot(english_coef, aes(x = term, y = abs(estimate), fill = term)) +
#   geom_bar(stat = "identity") +
#   geom_linerange(aes(ymin = abs(estimate) - 1.96 * std.error,
#                      ymax = abs(estimate) + 1.96 * std.error)) +
#   scale_fill_solarized(guide = FALSE) +
#   xlab("") +
#   ylab("Coefficient Magnitude\n") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# english_predictor_means <- english_data %>%
#   filter(aoa >= 6, aoa <= 25) %>%
#   mutate(aoa = cut(floor(aoa), 4)) %>% #breaks = c(4, 8, 12, 16, 20, 24))) %>%
#   gather_("predictor", "value", english_predictors) %>%
#   group_by(predictor, aoa) %>%
#   filter(!is.na(value)) %>%
#   multi_boot_standard(column = "value")
```

```{r, fig.width = 10, fig.height = 3}
# ggplot(english_predictor_means, aes(x = aoa, y = mean, color = predictor)) +
#   facet_grid(. ~ predictor) +
#   geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   geom_line(aes(group = predictor)) +
#   scale_colour_solarized(guide = FALSE) +
#   xlab("\nAge of Acquisition (months)") +
#   ylab("Mean Predictor Z-Score\n") +
#   theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

*  *  *  *
  
Analysis 2: Cross-Linguistic
----------------------------
  
```{r}
crossling_predictors <- c("frequency", "mlu", "num_characters", "concreteness",
                          "valence", "arousal", "babiness")

woof_concreteness <- unique(uni_joined$concreteness[uni_joined$uni_lemma == "woof woof"])
mean_babiness <- mean(filter(uni_joined, language == "English")$babiness, na.rm = TRUE)
mean_iconicity <- mean(filter(uni_joined, language == "English")$iconicity, na.rm = TRUE)
mean_valence <- mean(filter(uni_joined, language == "English")$valence, na.rm = TRUE)
mean_arousal <- mean(filter(uni_joined, language == "English")$arousal, na.rm = TRUE)

crossling_data <- uni_joined %>%
  filter(measure == "understands") %>%
  rowwise() %>%
  mutate(num_characters = num_characters(words),
#          valence = if (is.na(valence)) 5 else valence,
#          arousal = if (is.na(arousal)) 1 else arousal,
         valence = if (is.na(valence)) mean_valence else valence,
         arousal = if (is.na(arousal)) mean_arousal else arousal,
         concreteness = if (is.na(concreteness)) woof_concreteness else concreteness,
         babiness = if (is.na(babiness)) mean_babiness else babiness,
         iconicity = if (is.na(iconicity)) mean_iconicity else iconicity) %>%
  group_by(language, measure) %>%
  mutate_each_(funs(as.numeric(scale(.))), crossling_predictors)

crossling_na_lemmas <- crossling_data %>%
  select_(.dots = c("language", "uni_lemma", crossling_predictors)) %>%
  gather_("predictor", "value", crossling_predictors) %>%
  filter(is.na(value)) %>%
  group_by(language, uni_lemma) %>%
  summarise(num_na = n(), na_preds = paste(predictor, collapse = ", "))
```

```{r}
crossling_model_data <- crossling_data %>%
  ungroup() %>%
  select_(.dots = c("language", "lexical_class", "uni_lemma", "aoa",
                    crossling_predictors)) %>%
  filter(complete.cases(.)) %>%
  mutate(lexical_class = factor(lexical_class,
                                levels = c("nouns", "adjectives", "verbs",
                                           "function_words", "other"),
                                labels = c("Nouns", "Adjectives", "Verbs",
                                           "Function Words", "Other")))

crossling_model <- lmer(aoa ~ frequency + mlu + num_characters + concreteness + valence + 
                          arousal + babiness + (1 + frequency + mlu + num_characters + 
                                                  concreteness + valence + arousal + 
                                                  babiness | language),
                        data = crossling_model_data)

crossling_coef <- data.frame(term = row.names(summary(crossling_model)$coefficients),
                             estimate = summary(crossling_model)$coefficients[,"Estimate"],
                             std.error = summary(crossling_model)$coefficients[,"Std. Error"],
                             t = summary(crossling_model)$coefficients[,"t value"],
                             row.names = NULL) %>%
  filter(term != "(Intercept)")

crossling_sig <- data.frame(term = row.names(summary(crossling_model)$coefficients),
                             estimate = summary(crossling_model)$coefficients[,"Estimate"],
                             std.error = summary(crossling_model)$coefficients[,"Std. Error"],
                             row.names = NULL) %>%
  filter(term != "(Intercept)")

crossling_predictors_ordered <- crossling_predictors %>%
  factor(levels = crossling_coef$term[order(abs(crossling_coef$estimate))])

crossling_predictor_levels <- crossling_coef$term[order(abs(crossling_coef$estimate),
                                                        decreasing = TRUE)]
crossling_coef <- crossling_coef %>%
  mutate(term = factor(term, levels = crossling_predictor_levels))
```

```{r}
crossling_model_data <- crossling_data %>%
  ungroup() %>%
  select_(.dots = c("language", "lexical_category", "uni_lemma", "aoa",
                    crossling_predictors)) %>%
  filter(complete.cases(.)) %>%
  mutate(lexical_category = factor(lexical_category,
                                levels = c("nouns", "predicates",
                                           "function_words", "other"),
                                labels = c("Nouns", "Predicates",
                                           "Function Words", "Other")))
#   mutate(lexical_class = factor(lexical_class,
#                                 levels = c("nouns", "adjectives", "verbs",
#                                            "function_words", "other"),
#                                 labels = c("Nouns", "Adjectives", "Verbs",
#                                            "Function Words", "Other")))

crossling_coefs <- crossling_model_data %>%
  split(.$lexical_category) %>%
  map(function(crossling_lexcat_data) {
    crossling_model <- lmer(aoa ~ frequency + mlu + num_characters + concreteness + valence + 
                              arousal + babiness + (1 + frequency + mlu + num_characters + 
                                                      concreteness + valence + arousal + 
                                                      babiness | language),
                            data = crossling_lexcat_data)
    data.frame(lexical_category = unique(crossling_lexcat_data$lexical_category),
               term = row.names(summary(crossling_model)$coefficients),
               estimate = summary(crossling_model)$coefficients[,"Estimate"],
               std.error = summary(crossling_model)$coefficients[,"Std. Error"],
               row.names = NULL) %>%
      filter(term != "(Intercept)")
  }) %>%
  bind_rows()

# crossling_predictors_ordered <- crossling_predictors %>%
#   factor(levels = crossling_coef$term[order(abs(crossling_coef$estimate))])
# 
# crossling_predictor_levels <- crossling_coef$term[order(abs(crossling_coef$estimate),
#                                                         decreasing = TRUE)]
# crossling_coef <- crossling_coef %>%
#   mutate(term = factor(term, levels = crossling_predictor_levels))
```

```{r, fig.width = 12, fig.height = 8}
crossling_model_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels)) %>%
  #filter(language == "English") %>%
  ggplot(aes(x = value, y = aoa)) +
    facet_grid(language ~ predictor) +
    geom_jitter(aes(colour = lexical_category), size = 0.6, alpha = 0.3) +
    geom_smooth(aes(colour = lexical_category), method = "lm", se = FALSE, size = 1) +
    geom_smooth(color = "black", method = "lm", se = FALSE, size = 1) +
    scale_colour_solarized(name = "") +
    xlab("\nPredictor Z-Score") +
    ylab("Age of Acquisition (months)\n") +
    theme(legend.position = "bottom",
          legend.direction = "horizontal")
```

```{r, fig.width = 5, fig.height = 4}
# ggplot(crossling_coef, aes(x = term, y = abs(estimate), fill = term)) +
#   geom_bar(stat = "identity") +
#   geom_linerange(aes(ymin = abs(estimate) - 1.96 * std.error,
#                      ymax = abs(estimate) + 1.96 * std.error)) +
#   scale_fill_solarized(guide = FALSE) +
#   xlab("") +
#   ylab("Coefficient Magnitude\n") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# crossling_predictor_means_by_lang <- crossling_data %>%
#   filter(aoa <= 25) %>%
#   mutate(aoa = cut(floor(aoa), breaks = c(4, 8, 12, 16, 20, 24))) %>%
#   gather_("predictor", "value", crossling_predictors) %>%
#   group_by(language, predictor, aoa) %>%
#   filter(!is.na(value)) %>%
#   multi_boot_standard(column = "value")
```

```{r, fig.width = 10, fig.height = 4}
# crossling_predictor_means_by_lang %>%
#   ungroup() %>%
#   mutate(predictor = factor(predictor, levels = c(english_predictor_levels,
#                                                   "num_characters"))) %>%
#   ggplot(aes(x = aoa, y = mean, color = language)) +
#   facet_grid(. ~ predictor) +
#   geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   geom_line(aes(group = language)) +
#   scale_colour_solarized(name = "") +
#   xlab("\nAge of Acquisition (months)") +
#   ylab("Mean Predictor Z-Score\n") +
#   theme(axis.text.x = element_text(angle = 30, hjust = 1),
#         legend.position = "bottom",
#         legend.direction = "horizontal")
```

```{r}
# crossling_predictor_means <- crossling_data %>%
#   filter(aoa < 25) %>%
#   mutate(aoa = cut(floor(aoa), breaks = c(4, 8, 12, 16, 20, 24))) %>%
#   gather_("predictor", "value", crossling_predictors) %>%
#   group_by(predictor, aoa) %>%
#   filter(!is.na(value)) %>%
#   multi_boot_standard(column = "value")
```

```{r, fig.width = 10, fig.height = 3}
# crossling_predictor_means %>%
#   ungroup() %>%
#   mutate(predictor = factor(predictor, levels = c(english_predictor_levels,
#                                                   "num_characters"))) %>%
#   ggplot(aes(x = aoa, y = mean, color = predictor)) +
#   facet_grid(. ~ predictor) +
#   geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   geom_line(aes(group = predictor)) +
#   scale_colour_solarized(guide = FALSE) +
#   xlab("\nAge of Acquisition (months)") +
#   ylab("Mean Predictor Z-Score\n") +
#   theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
lang_predictors <- c("frequency", "mlu", "concreteness", "num_characters",
                        "valence", "arousal", "babiness")
# "iconicity" "dominance" "num_syllables" "num_phonemes"

lang_data_fun <- function(uni_joined, lang, lang_predictors, num_characters) {
  
  woof_concreteness <- unique(uni_joined$concreteness[uni_joined$uni_lemma == "woof woof"])
  mean_babiness <- mean(filter(uni_joined, language == "English")$babiness, na.rm = TRUE)
  mean_iconicity <- mean(filter(uni_joined, language == "English")$iconicity, na.rm = TRUE)
  mean_valence <- mean(filter(uni_joined, language == "English")$valence, na.rm = TRUE)
  mean_arousal <- mean(filter(uni_joined, language == "English")$arousal, na.rm = TRUE)

  lang_data <- uni_joined %>%
    filter(language == lang, measure == "understands") %>%
    rowwise() %>%
    mutate(num_characters = num_characters(words),
           #valence = if (is.na(valence)) 5 else valence,
           #arousal = if (is.na(arousal)) 1 else arousal,
           valence = if (is.na(valence)) mean_valence else valence,
           arousal = if (is.na(arousal)) mean_arousal else arousal,
           concreteness = if (is.na(concreteness)) woof_concreteness else concreteness,
           babiness = if (is.na(babiness)) mean_babiness else babiness,
           iconicity = if (is.na(iconicity)) mean_iconicity else iconicity) %>%
    ungroup() %>%
    #  mutate(valence = abs(valence - 5)) %>%
    group_by(language, measure) %>%
    mutate_each_(funs(as.numeric(scale(.))), lang_predictors)
  
  return(lang_data)
}

langs <- unique(uni_joined$language)
lang_data_list <- map(langs,
                      function(lang) lang_data_fun(uni_joined, lang,
                                                   lang_predictors, num_characters))
names(lang_data_list) <- langs

# english_na_lemmas <- english_data %>%
#   select_(.dots = c("uni_lemma", english_predictors)) %>%
#   gather(predictor, value, -uni_lemma) %>%
#   filter(is.na(value)) %>%
#   group_by(uni_lemma) %>%
#   summarise(num_na = n(), na_preds = paste(predictor, collapse = ", "))
  
lang_model_data_fun <- function(lang_data, lang_predictors) {
  
  lang_model_data <- lang_data %>%
    ungroup() %>%
    select_(.dots = c("language", "lexical_category", "uni_lemma", "aoa", lang_predictors)) %>%
    filter(complete.cases(.)) %>%
    mutate(lexical_category = factor(lexical_category,
                                  levels = c("nouns", "predicates",
                                             "function_words", "other"),
                                  labels = c("Nouns", "Predicates",
                                             "Function Words", "Other")))
  return(lang_model_data)
}

lang_model_data_list <- map(lang_data_list,
                            function(lang_data) lang_model_data_fun(lang_data, lang_predictors))

lang_model_fun <- function(lang_model_data, lang_predictors) {

  if (nrow(lang_model_data) > 0) {
    lang_formula <- as.formula(
      sprintf("aoa ~ %s", paste(lang_predictors, collapse = " + "))
    )
    
    lang_model <- lm(lang_formula, data = lang_model_data, y = TRUE)
    return(lang_model)
  }
}

lang_model_list <- map(lang_model_data_list,
                       function(lang_model_data) lang_model_fun(lang_model_data,
                                                                lang_predictors))

# lang_predictions_fun <- function(lang_model_data, lang_model) {
#   lang_predictions <- lang_model_data
#   lang_predictions$predicted_aoa <- lang_model$fitted.values
#   return(lang_predictions)
# }
# 
# lang_cor <- function(lang_predictions) {
#   cor(lang_predictions$aoa, lang_predictions$predicted_aoa)
# }
#   
# lang_predictions_list <- map(lang_model_data_list,
#                              function(lang_model_data) lang_predictions_fun(lang_model_data, lang_model))

lang_coef <- function(lang_model) {
  tidy(lang_model) %>%
    filter(term != "(Intercept)")
}

lang_coef_list <- map(lang_model_list, lang_coef)
# english_predictors_ordered <- english_predictors %>%
#   factor(levels = english_coef$term[order(abs(english_coef$estimate))])
# 
# english_predictor_levels <- english_coef$term[order(abs(english_coef$estimate),
#                                                    decreasing = TRUE)]
lang_coef <- map(names(lang_coef_list),
                 function(lang) lang_coef_list[[lang]] %>% mutate(language = lang)) %>%
  bind_rows()

lang_coef <- lang_coef %>%
  mutate(term = factor(term, levels = english_predictor_levels))
```

```{r, fig.width = 5, fig.height = 4}
crossling_coef %>%
  mutate(language = "Cross-Linguistic") %>%
  bind_rows(lang_coef) %>%
  mutate(language = factor(language, levels = c(langs, "Cross-Linguistic"))) %>%
  ggplot(aes(x = term, y = abs(estimate), fill = term)) +
    facet_wrap(~language, ncol = 4) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = abs(estimate) - 1.96 * std.error,
                       ymax = abs(estimate) + 1.96 * std.error)) +
    scale_fill_solarized(guide = FALSE) +
    xlab("") +
    ylab("Coefficient Magnitude\n") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
crossling_predictor_smooth <- crossling_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  filter(!is.na(value)) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels))

ggplot(crossling_predictor_smooth, aes(x = aoa, y = value, colour = predictor)) +
  facet_grid(. ~ predictor) +
  #geom_smooth(method = "lm", formula = y ~ poly(x, 4)) +
  geom_smooth(method = "loess", span = 1) +
  scale_colour_solarized(guide = FALSE) +
  scale_x_continuous(name = "Age of Acquisition (months)",
                     breaks = seq(5, 30, 5)) +
  ylab("Mean Predictor Z-Score")
```

*  *  *  *
  
Summary Plots
-------------

```{r}
joined_coef <- bind_rows(mutate(english_coef, type = "English"),
                         mutate(crossling_coef, type = "Cross-Linguistic")) %>%
  mutate(type = factor(type, levels = c("English", "Cross-Linguistic")),
         term = factor(term, levels = english_predictor_levels))
```

```{r, fig.width = 7, fig.height = 4}
# ggplot(joined_coef, aes(x = term, y = abs(estimate), fill = term)) +
#   facet_wrap("type", scales = "free_x") +
#   geom_bar(stat = "identity") +
#   geom_linerange(aes(ymin = abs(estimate) - 1.96 * std.error,
#                      ymax = abs(estimate) + 1.96 * std.error)) +
#   scale_fill_solarized(guide = FALSE) +
#   xlab("") +
#   ylab("Coefficient Magnitude\n") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
english_predictor_means_2 <- english_data %>%
  filter(floor(aoa) > 4, floor(aoa) <= 24) %>%
  mutate(aoa = cut(floor(aoa), breaks = c(4, 14, 24))) %>%
  gather_("predictor", "value", english_predictors) %>%
  group_by(predictor, aoa) %>%
  filter(!is.na(value)) %>%
  multi_boot_standard(column = "value")

crossling_predictor_means_2 <- crossling_data %>%
  filter(floor(aoa) > 4, floor(aoa) <= 24) %>%
  mutate(aoa = cut(floor(aoa), breaks = c(4, 14, 24))) %>%
  gather_("predictor", "value", crossling_predictors) %>%
  group_by(predictor, aoa) %>%
  filter(!is.na(value)) %>%
  multi_boot_standard(column = "value")

level_base <- english_predictor_means_2 %>% filter(aoa == "(4,14]")
predictor_mean_levels <- level_base$predictor[order(level_base$mean, decreasing = TRUE)]

joined_predictor_means <- bind_rows(
  mutate(english_predictor_means_2, type = "English"),
  mutate(crossling_predictor_means_2, type = "Cross-Linguistic")) %>%
  mutate(type = factor(type, levels = c("English", "Cross-Linguistic")))
```

```{r, fig.width = 8, fig.height = 4}
# joined_predictor_means %>%
#   mutate(predictor = factor(predictor, levels = predictor_mean_levels)) %>%
#   ggplot(aes(x = aoa, y = mean, color = predictor)) +
#   facet_wrap(~type) +
#   geom_point(position = position_dodge(width = 0.1)) +
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper, group = predictor),
#                  alpha = 0.4,
#                  position = position_dodge(width = 0.1)) +
#   geom_line(aes(group = predictor), position = position_dodge(width = 0.1)) +
#   geom_dl(aes(label = predictor),
#           method = list("first.qp", dl.trans(x = x - 0.3), cex = 0.6)) +
#   geom_dl(aes(label = predictor),
#           method = list("last.qp", dl.trans(x = x + 0.3), cex = 0.6)) +
#   scale_colour_solarized(guide = FALSE) +
#   xlab("\nAge of Acquisition (months)") +
#   ylab("Mean Predictor Z-Score\n")
```

```{r}
rsq <- function(object) {
  1 - sum(residuals(object, type = "response") ^ 2) / sum((object$y - mean(object$y)) ^ 2)
}

adj_rsq <- function(object) {
  rsq <- rsq(object)
  p <- summary(object)$df[1] - 1  # p
  n_p <- summary(object)$df[2]  # n - p - 1
  rsq - (1 - rsq) * (p / n_p)
}

eng_adj_rsq <- adj_rsq(english_model)

lang_adj_rsq <- lang_model_list %>%
  compact() %>%
  map(adj_rsq)

crossling_fit <-  lm(model.response(model.frame(crossling_model)) ~ fitted(crossling_model),
                     y = TRUE)
crossling_adj_rsq <- adj_rsq(crossling_fit)

all_adj_rsq <- lang_adj_rsq
all_adj_rsq$`Cross-Linguistic` <- crossling_adj_rsq

crossling_fit_data <- data.frame(observed = model.response(model.frame(crossling_model)),
                                 fitted = fitted(crossling_model))
ggplot(crossling_fit_data, aes(x = fitted, y = observed)) +
  geom_point() +
  geom_smooth(method = "lm") +
  coord_fixed()
```
