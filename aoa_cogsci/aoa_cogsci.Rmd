---
title: |
  | From _uh-oh_ to _tomorrow_
  | Predicting age of acquisition for early words across languages
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Mika Braginsky} \\ \texttt{mikabr@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Daniel Yurovsky} \\ \texttt{yurovsky@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Virginia A. Marchman} \\ \texttt{marchman@stanford.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@stanford.edu} \\ Department of Psychology \\ Stanford University}

abstract: 
    "_[TODO: abstract]_"
    
keywords:
    "language acquisition; word learning; development"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width = 3, fig.height = 3, fig.crop = F,
                      fig.pos = "tb", fig.path = 'figs/', echo = F,
                      warning = F, cache = F, message = F, sanitize = T)
```

```{r, libraries}
library(knitr)
library(png)
library(grid)
library(xtable)
library(ggplot2)
library(langcog)
library(dplyr)
library(tidyr)
library(purrr)
# library(extrafont)
# loadfonts(quiet = TRUE)
font <- "Times"
theme_set(theme_mikabr(base_size = 12, base_family = font) +
            theme(legend.key = element_blank(),
                  legend.background = element_rect(fill = "transparent"),
                  legend.margin = unit(0, "mm"),
                  panel.background = element_blank(),
                  panel.margin = unit(1, "mm"),
                  plot.margin = unit(c(0, 0, 0, 0), "mm")))
    
# setwd("..")
# knit("aoa_prediction_funs.Rmd", tangle = TRUE)
# source("aoa_prediction_funs.R")
# save.image("aoa_prediction.RData")

load("../aoa_prediction.RData")
```

# Introduction

One of the central problems facing a child acquiring their first language is to learn word meanings. Learners must integrate multiple information sources to figure out how to map the wordforms they hear onto representations of their meanings. Across many labratory experiments and small-scale models, a number of strategies have emerged as plausible components of word learning, including tracking co-occurence statistics between words and referents to deduce word meaning across situations; attending to social cues like pointing and eye gaze to direct hypothesis search; relying on certain biases, such as priviledging basic level category labels, to constrain inference; drawing on knowledge of relations between words to use known meanings to learn new ones; and so on.

Each of these abilities has been reliably demonstrated in the constrained learning contexts of the laboratory, indicating that they could be used for word learning. But it is less clear to what extent children actually employ them in the natural word learning environment and how they interact to create the longer-term dynamics of vocabulary acquisition. How do various word learning mechanisms differ in their relative contributions, and how does that change over the course of development?

One way to address these questions is to use naturalistic large-scale vocabulary development data to examine the contribution of various theoretically-relevant factors to vocabulary growth. We can look across children to determine how easy or hard various words are to learn, and then examine the relationship between words' difficulties and various word properties that relate to proposed word learning mechanisms. Foundational work using such an approach has revealed that in English, within lexical category, words that are more frequent in speech to children are likely to be learned earlier [@goodman2008; @roy2009]. Further studies have delved into the relevance of semantic networks [@hills2009], neighborhood density [@stokes2010], iconocity [@perry2015], and linguistic distinctiveness [@roy2015] to vocabulary construction.

However, the previous studies use different datasets, focus on different predictors, and for the most part only analyze English data. It is thus impossible to compare the relative importance of the many relevant factors and to draw robust conclusions. To remedy this issue, we present analyses based on data from Wordbank (wordbank.stanford.edu), an open repository of language development data. By aggregating administrations of the MacArthur-Bates Communicative Development Inventory [CDI; @fenson2007], a family of parent-report vocabulary checklists, Wordbank provides large-scale vocabulary data that we use to conduct analyses over development and across languages.

We integrate Wordbank data with characterizations of the word learning environment from the CHILDES database [@macwhinney2000] and elsewhere, a multiple data source approach pioneered by @goodman2008. Building on their work, we want to move beyond frequency to examine a variety of information sources. We specifically follow @roy2015 in predicting age of acquisition (AoA) as a function of several different environment predictors. In analyzing a high-density longitudinal corpus for a single English-acquiring child, Roy et al found that frequency, number of characters, and mean length of utterances were predictive of the age of a word's first production. Due to the nature of the data, this analysis was limited to one language (in fact to one subject) and could only test production, distancing the connection between properties of the input and the child's emerging understanding of words.

Our approach provides a complimentary analysis by using CDI comprehension data to look at earliest words, across languages. We estimate the age of acquisition for around 400 words in each of `r length(unique(lang_coef$language))` languages. We also estimate each words' frequency and mean length of utterances (MLU) in which it appears, as well as obtaining ratings of each words' concreteness, valence, arousal, and relevance to babies from previously collected norms. We then predict words' AoA from all of these properties, and assess the relative contributions of each factor, along with the interaction of predictors with the lexical category and their changes over development. Each of these analyses has the potential to provide leverage on long-standing theoretical questions. 

A first theoretical question of interest is which lexical categories are most influenced by input-related factors like frequency and utterance length compared with conceptual factors like concreteness or valence. For example, "division of dominance" theory suggests that nouns might be more sensitive to cognitive factors while predicates and closed-class words might be more sensitive to linguistic factors [@gentner2001]. On the other hand, on syntactic bootstrapping theories, nouns are argued to be learned via frequent co-occurrence (operationalized by frequency) while verbs might be more sensitive to syntactic factors (operationalized here by utterance length) [@gleitman1990], and neither would be particularly sensitive to conceptual complexity [@snedeker2007]. 

A second question of interest is the variability across languages in the relative importance of predictors. For example, are there differences in the importance of syntactic factors in morphologically more complex languages like Russian and Turkish, compared with simpler ones like English? Differences of this type might be revealing of the degree to which learners face different challenges in different language environments. Or consistency may suggest the operation of similar learning mechanisms and strategies that are not as dependent on the complexities of phonology, morphology, and syntax in a particular language. 

Overall, by incorporating a variety of theoretically-important factors, as well as basing our analysis on a large samples of words and children and building towards more cross-linguistic coverage, our study presents a more thorough investigatation of the question of what properties determine words' learnability.


```{r data, fig.height=7, fig.width=7, fig.env='figure*', fig.align='center', fig.pos='!h', dev='cairo_pdf', fig.cap='Relationship between predictors and AoA for each lexical category in each language.'}
crossling_model_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels),
         lexical_category = factor(lexical_category,
                                   labels = paste(levels(lexical_category), "  "))) %>%
  #filter(language == "English") %>%
  ggplot(aes(x = value, y = aoa)) +
    #facet_wrap(~predictor, ncol = 4) +
    facet_grid(language ~ predictor, scales = "free_x") +
    geom_point(aes(fill = lexical_category), colour = NA,
               size = 0.5, alpha = 0.4, shape = 21) +
    geom_smooth(aes(colour = lexical_category), method = "lm", se = FALSE, size = 0.8) +
    geom_smooth(color = "black", method = "lm", se = FALSE, size = 0.8) +
    scale_colour_solarized(name = "") +
    scale_fill_solarized(name = "") +
    xlab("Predictor z-Score") +
    scale_y_continuous(name = "Age of Acquisition (months)",
                       breaks = seq(5, 25, 5)) +
    #theme_mikabr(base_size = 10) +
    theme(legend.position = "top")
```

# Data

We use Wordbank (wordbank.stanford.edu), an open database of developmental vocabulary data, to estimate the age of acquisition for words across `r length(unique(lang_coef$language))` languages: `r paste(unique(lang_coef$language), collapse = ", ")`. We then ask what factors are most important for predicting this age of acquisition.

## Estimating Age of Acquisition

To estimate the age at which words are acquired, we took vocabulary data collected using the MacArthur-Bates Communicative Development Inventory, a family of parent-report checklists, specifically the Words & Gestures (infant) form for 8- to 18-month-olds. When filling out a CDI a form, parents are asked to indicate whether their child understands and/or says each of around 400 words. From these data, for each word on the CDI, we computed the proportion of children at each age that are reported to understand the word. We then fit a logistic curve to these proportions using robust fitting of a generalized linear model and determine when the curve crosses 0.5, i.e. at what age at least 50% of children are reported to understand the word. This point is taken to be the words' age of acquisition.

## Predictors

Each of our predictors are derived from independent resources. For each word that appears on the CDI Word & Gestures form in each of our `r length(unique(lang_coef$language))` languages, we obtained an estimate of its frequency in child-directed speech, the mean utterance length (MLU) of sentences in which if appears in child-directed speech, its length in characters, and ratings of its concreteness, valence, arousal, and relevance to babies. While frequency and MLU are measured relative to the word's language, since the conceptual ratings were collected only in English, we mapped all the words onto translation equivalents across CDI forms, allowing us to use the ratings for English words cross-linguistically. While imperfect, this method allows us to examine languages for which limited resources exist.

Items such as _child's own name_ were excluded in all languages. Each predictor was also centered and scaled so that they would all have comparable units. Lexical category was determined on the basis of the conceptual categories presented on the CDI form, such that Nouns is common nouns, Predicates is verbs and adjectives, Function Words is closed-class words, and Other is the remaining items.

__Frequency__: For each language, we estimated word frequency from unigram count in all corpora in the CHILDES database for that language, normalized to the length of the corpus. Each word's count includes the counts of words that share the same stem (so that _dogs_ counts as _dog_) or are synonymous (so that _father_ counts as _daddy_). For polysemous word pairs, such as _orange_ as in color and _orange_ as in fruit, each occurence of _orange_ in the corpus counts for both. Finally, each word's frequency estimate is taken as the log of its count.

__MLU__: For each language, we estimated each word's MLU by calculating the mean number of words in the sentences in which that word appears in all corpora in the CHILDES database for that language. Words that only occur in one sentence were excluded.

__Length__: We computed the number of characters in each word in each language, which is known to be highly correlated with number of phonemes and syllables.

__Concreteness__: We used previously collected norms for concreteness [@brysbaert2014], which were gathered by asking adult participants to rate how concrete the meaning of each word is by using a 5-point scale from abstract to concrete. For the `r nrow(filter(uni_concreteness, is.na(concreteness))) - 2` CDI words that weren't part of the collected norms (mostly animal sounds such as _baa baa_), we imputed a conreteness rating from the mean of all CDI words' concreteness rating.

__Valence and Arousal__: We also used previously collected norms for valence and arousal [@warriner2013], for which adult participants are asked to rate words on a 1-9 happy-unhappy scale (valence) and 1-9 excited-calm scale (arousal). For the `r nrow(filter(uni_valences, is.na(valence))) - 2` CDI words that weren't part of the collected norms (mostly function words such as _her_), we imputed ratings from the mean of all CDI words' ratings.

__Babiness__: Lastly, we used previously collected norms of "babiness", a measure of association with infancy [@perry2015] for which adult participants are asked to judge how relevant to babies a word is.

```{r lang_stats, results="asis"}
library(wordbankr)
num_admins <- get_administration_data(mode = "remote") %>%
  filter(form == "WG") %>%
  group_by(language) %>%
  summarise(num_admins = n())

# num_words <- words %>%
#   group_by(language) %>%
#   summarise(num_words = n())

aoa_stats <- crossling_model_data %>%
  group_by(language) %>%
  summarise(num_included = n())
            #mean_aoa = mean(aoa),
            #var_aoa = var(aoa))

childes_stats <- read.csv("../predictors/frequency/num_words.csv") #%>%
  #mutate(num_words = formatC(num_words, big.mark = ","))

lang_stats <- aoa_stats %>%
  #left_join(num_words) %>%
  left_join(num_admins) %>%
  left_join(childes_stats)
colnames(lang_stats) <- c("Language", "CDI Items", "CDI Admins", "CHILDES Words")
                          #"Mean AoA",, "Var AoA")

lang_table <- xtable(lang_stats, digits = 2, caption = "Dataset statistics")

print(lang_table, type = "latex", comment = FALSE, include.rownames = FALSE,
      table.placement = "t", format.args = list(big.mark = ","))
```

```{r extremes, results="asis"}
num_extremes <- 3
extremes <- crossling_model_data %>%
    split(.$language) %>%
    map_df(function(lang_data) {
    map_df(c("aoa", rev(levels(crossling_predictors_ordered))), function(predictor) {
      highest <- lang_data %>%
        arrange_(as.formula(sprintf("~desc(%s)", predictor))) %>%
        .$uni_lemma %>%
        .[1:num_extremes]
      lowest <- lang_data %>%
        arrange_(predictor) %>%
        .$uni_lemma %>%
        .[1:num_extremes]
      return(data.frame("language" = unique(lang_data$language), "Measure" = predictor,
                        "Lowest" = paste(lowest, collapse = ", "),
                        "Highest" = paste(highest, collapse = ", ")))
    })
  }) %>%
  filter(language == "English") %>%
  select(-language)

extremes_table <- xtable(extremes, caption = "Examples of words with the lowest and highest values for age of acquisition and each predictor.")

print(extremes_table, type = "latex", comment = FALSE, include.rownames = FALSE,
      table.placement = "!hb", floating.environment = "table*")
```


# Analysis

An overview of our entire dataset can be seen in Figure \ref{fig:data}, which shows each word's estimated age of acquisition against its predictor values, separated by language and lexical category. We present three analyses of these data: 1) how the word properties change over development, 2) their relative contributions to predicting AoA, and 3) their interaction with lexical category.

## Developmental Trajectory

To assess developmental trends, we examine how the values of each predictor change as a function of estimated AoA. Figure \ref{fig:devo} shows these trajectories, with a cubic curve smoothing over all words. Words that are learned earlier are more frequent, higher in babiness, and appear in shorter sentences. Concreteness exhibits a U-shaped trajectory, with the earliest learned words actually being relatively abstract, such as many social routines and animal sounds.

```{r devo, fig.height=3, fig.width=3, fig.env='figure', fig.align='center', dev='cairo_pdf', fig.cap='Predictor values over development.'}
crossling_data %>%
  gather_("predictor", "value", crossling_predictors) %>%
  filter(!is.na(value)) %>%
  mutate(predictor = factor(predictor, levels = crossling_predictor_levels,
                            labels = paste(crossling_predictor_levels, " "))) %>%
  ggplot(aes(x = aoa, y = value, colour = predictor)) +
    #facet_wrap(~predictor, ncol = 4) +
    #geom_point(size = 0.5, alpha = 0.2) +
    #geom_smooth(method = "loess", se = FALSE, span = 0.75) +
    geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
    geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
    scale_colour_solarized(name = "", guide = guide_legend(nrow = 4, byrow = FALSE)) +
    scale_x_continuous(name = "Age of Acquisition (months)",
                       breaks = seq(0, 30, 5)) +
    scale_y_continuous(name = "Predictor Z-Score",
                       breaks = seq(-1.5, 1.5, 0.5)) +
    theme(legend.position = c(0.64, 0.13),
          legend.direction = "horizontal",
          legend.key.height = unit(0.7, "lines"),
          legend.key.width = unit(0.7, "lines"),
          legend.text = element_text(size = 8))
```

## Predicting AoA

```{r}
predict_english <- function(english_predictors) {
  english_model_data <- english_model_data_fun(english_data_fun(uni_joined,
                                                                english_predictors,
                                                                num_characters),
                                               english_predictors)
  english_predictions_fun(english_model_data,
                          english_model_fun(english_model_data, english_predictors))
}
english_predictors <- c("frequency",  "concreteness", "num_characters",
                        "valence", "arousal", "babiness")
predictions <- predict_english(english_predictors)
predictions <- predictions %>%
    mutate(lexical_category = factor(lexical_category,
                                     levels = levels(lexical_category),
                                     labels = paste0(levels(lexical_category), "  ")),
           error = abs(predicted_aoa - aoa))

cors <- predictions %>%
  group_by(lexical_category) %>%
  summarise(cor = cor(aoa, predicted_aoa))
```

```{r fit, fig.height=2.3, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='English model fit.'}
threshold <- 6
predictions %>%
  ggplot(aes(x = predicted_aoa, y = aoa)) +
    facet_wrap(~lexical_category, ncol = 4) +
    geom_point(aes(colour = lexical_category), size = 0.7,
               data = filter(predictions, error < threshold)) +
    geom_label(aes(label = uni_lemma, colour = lexical_category), family = font,
              show.legend = FALSE, data = filter(predictions, error >= threshold),
              label.padding = unit(0.15, "lines"), size = 3) +
    geom_smooth(aes(colour = lexical_category), weight = 1, method = "lm", se = FALSE) +
    geom_smooth(colour = "black", weight = 2, method = "lm") +
    scale_colour_solarized(name = "", guide = FALSE) +
    scale_x_continuous(name = "Model Predicted AoA (months)",
                       breaks = seq(5, 25, by = 5), limits = c(5, 25)) +
    scale_y_continuous(name = "AoA (months)",
                       breaks = seq(5, 25, by = 5), limits = c(5, 25)) +
    geom_text(aes(x = 8, y = 24.5, label = sprintf("r = %.2f", cor)),
              data = cors, family = font, size = 2.8)
```

We fit a linear regression for each language's data, as well as a linear mixed-effects model with language as a random effect for all the data pooled. For illustrative purposes, Figure \ref{fig:fit} compares the predictions of the model to AoA estimates, for only English data, with outliers labelled.

```{r coefs, fig.height=3.5, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Magnitudes of predictor coefficients.'}
plot_coefs <- crossling_coef %>%
  mutate(language = "Cross-Linguistic") %>%
  bind_rows(lang_coef) %>%
  mutate(language = factor(language, levels = c("Cross-Linguistic", langs)),
         term = factor(term, levels = rev(levels(term))),
         sign = factor(sign(estimate)))

ggplot(plot_coefs, aes(x = term, y = abs(estimate))) +
  facet_wrap(~language, ncol = 4) +
  geom_rect(data = filter(plot_coefs, language == "Cross-Linguistic"),
            aes(fill = language), xmin = -Inf, xmax = Inf,
            ymin = -Inf, ymax = Inf, alpha = 0.03) +
  geom_linerange(aes(colour = term,
                     ymin = abs(estimate) - 1.96 * std.error,
                     ymax = abs(estimate) + 1.96 * std.error)) +
  geom_point(aes(colour = term, shape = sign), size = 2.5) +
#     geom_pointrange(aes(ymin = abs(estimate) - 1.96 * std.error,
#                         ymax = abs(estimate) + 1.96 * std.error,
#                         shape = sign)) +
  geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
#    geom_text(aes(label = paste("bar(R)^2==", adj_rsq)), parse = TRUE,
  geom_text(aes(label = paste("bar(R)^2==", adj_rsq)), parse = TRUE,
            x = 1, y = 1.8, family = font, size = 2.8,
            data = data.frame(language = names(all_adj_rsq),
                              adj_rsq = round(unlist(all_adj_rsq), 2),
                              row.names = NULL)) +
  coord_flip() +
  scale_fill_solarized(guide = FALSE) +
  scale_colour_manual(guide = FALSE, values = rev(solarized_palette(7))) +
  scale_shape_manual(name = "", values = c(1, 19),
                     labels = c("negative", "positive")) +
  xlab("") +
  scale_y_continuous(name = "Coefficient Magnitude (Months/SD)",
                     breaks = seq(0, 2, 0.5)) +
  theme(legend.position = c(0.87, -0.1),
        legend.direction = "horizontal",
        legend.key.height = unit(0.5, "lines"),
        legend.key.width = unit(0.5, "lines"))
```

Figure \ref{fig:coefs} shows the magnitude and direction of the coefficient for each predictor in each language and cross-linguistically. We find that frequency, babiness, concreteness, and MLU are relatively stronger predictors of age of acquisition, across languages and in the cross-linguistic model. Overall there's considerable consistency in how the predictors pattern in various languages, although with interesting differences: for example, MLU in English appears to be unusually strong, while frequency in Spanish look unusually weak. There is also variability in the overall fit of the models to the data, with some languages, such as Norwegian, having relatively more of the variance explained than others, such as Turkish.

```{r coefs_lexcat, fig.height=1.7, fig.width=7, fig.env='figure*', fig.align='center', dev='cairo_pdf', fig.cap='Magnitudes of predictor coefficients by lexical category.'}
crossling_coefs %>%
  filter(term %in% c("frequency", "babiness", "concreteness", "mlu")) %>%
  mutate(term = factor(term, levels = rev(crossling_predictor_levels)),
         sign = factor(sign(estimate))) %>%
  ggplot(aes(x = term, y = abs(estimate), colour = term)) +
    facet_wrap(~lexical_category, ncol = 4) +
    geom_linerange(aes(ymin = abs(estimate) - 1.96 * std.error,
                        ymax = abs(estimate) + 1.96 * std.error)) +
    geom_point(aes(shape = sign), size = 2.5) +
#     geom_pointrange(aes(ymin = abs(estimate) - 1.96 * std.error,
#                        ymax = abs(estimate) + 1.96 * std.error)) +
    geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
    coord_flip() +
    scale_colour_manual(guide = FALSE, values = rev(solarized_palette(7))[4:7]) +
    scale_shape_manual(name = "", values = c(1, 19),
                       labels = c("negative", "positive")) +
    xlab("") +
    scale_y_continuous(name = "Coefficient Magnitude (Months/SD)",
                       breaks = seq(0, 2.5, 0.5)) +
    theme(legend.position = c(0.87, -0.26),
          legend.direction = "horizontal",
          legend.key.height = unit(0.5, "lines"),
          legend.key.width = unit(0.5, "lines"))
```

## Lexical Category

Previous work gives reason to believe that predictors' relationship with age of acquisition differs among various lexical categories [@goodman2008]. To investigate these effects, we break down our data by lexical category and fit separate cross-linguistic linear mixed-effects models for each one. Figure \ref{fig:coefs_lexcat} shows the magnitudes and directions of the resulting coefficients, leaving off the less strong predictors. We find that frequency matters most for Nouns and comparatively little for Function Words, while MLU is irrelevant for both Nouns and Predicates, but highly informative for Function Words and Other items.

_[TODO: give more examples everywhere of specific words that are low/high in AoA, predictor values]_

_[TODO: mention predictors' correlations to each other]_

_[TODO: mention that predictors have different variabilities, that probably matters]_

_[TODO: emphasize the sketchiness of using ratings cross-linguistically]_

\newpage

# Discussion

Overall, we find that while frequency is predictive of age of acquisition across languages, conceptual factors are at least as important, especially for the earliest learned words. Our results imply that distributional theories of word learning should be constrained by such conceptual factors, which are likely to apply across languages. _[TODO: actually say something]_

# Acknowledgements

Thanks to the MacArthur-Bates CDI Advisory Board.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
