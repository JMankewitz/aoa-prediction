---
title: AoA modeling
output:
  html_notebook:
    highlight: tango
    theme: spacelab
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(glue)
library(broom)
library(langcog)
library(jglmm)
```

```{r load_data}
load("../saved_data/uni_joined.RData")

predictors <- c("frequency", "MLU", "final_frequency", "solo_frequency",
                "num_phons", "concreteness", "valence", "arousal", "babiness")
.alpha <- 0.05
```

Impute and scale data for input into models.
```{r uni_model_data}
model_data <- uni_joined %>%
  select(language, uni_lemma, lexical_classes, !!predictors) %>%
  distinct() %>%
  mutate(lexical_category = if_else(
           str_detect(lexical_classes, ","), "other", lexical_classes
         ) %>%
           as_factor() %>%
           fct_collapse("predicates" = c("verbs", "adjectives", "adverbs"))) %>%
  select(-lexical_classes) %>%
  group_by(language) %>%
  mutate_at(vars(!!predictors), funs(as.numeric(scale(.)))) %>%
  nest()

pred_sources <- list(
  c("frequency", "MLU", "final_frequency", "solo_frequency"),
  c("valence", "arousal"),
  "concreteness", "babiness", "num_phons"
)

fit_predictor <- function(pred, d) {
  xs <- pred_sources %>% discard(~pred %in% .x) %>% unlist()
  x_str <- xs %>% paste(collapse = " + ")
  lm(as.formula(glue("{pred} ~ {x_str}")), data = d) %>%
    augment(newdata = d) %>%
    select(uni_lemma, lexical_category, .fitted)
}

max_steps <- 20
iterate_predictors <- function(lang_data) {
  missing <- lang_data %>%
    gather(predictor, value, !!predictors) %>%
    mutate(missing = is.na(value)) %>%
    select(-value) %>%
    spread(predictor, missing)
  predictor_order <- lang_data %>%
    gather(predictor, value, !!predictors) %>%
    group_by(predictor) %>%
    summarise(num_na = sum(is.na(value))) %>%
    filter(num_na != 0) %>%
    arrange(num_na) %>%
    pull(predictor)
  imputation_data <- lang_data %>%
    mutate_at(vars(!!predictors),
              funs(as.numeric(Hmisc::impute(., fun = "random"))))
  for (i in 0:max_steps) {
    pred <- predictor_order[(i %% length(predictor_order)) + 1]
    imputation_fits <- fit_predictor(pred, imputation_data)
    imputation_data <- missing %>%
      select(uni_lemma, lexical_category, !!pred) %>%
      rename(missing = !!pred) %>%
      right_join(imputation_data) %>%
      left_join(imputation_fits) %>%
      mutate_at(vars(pred), funs(if_else(is.na(missing), .fitted, .))) %>%
      select(-.fitted, -missing)
  }
  return(imputation_data)
}

model_data_imputed <- model_data %>%
  mutate(imputed = map(data, iterate_predictors))

uni_model_data <- model_data_imputed %>%
  select(-data) %>%
  unnest() %>%
  group_by(language) %>%
  mutate_at(vars(predictors), funs(as.numeric(scale(.)))) %>%
  right_join(uni_joined %>% select(language, measure, uni_lemma, age, num_true,
                                   num_false)) %>%
  group_by(language, measure) %>%
  mutate(unscaled_age = age, age = scale(age),
         total = as.double(num_true + num_false), prop = num_true / total)
```

Save point -- model input data.
```{r uni_model_data_save}
save(uni_model_data, file = "../saved_data/uni_model_data.RData")
# load("../saved_data/uni_model_data.RData")
```

Fit models for each language and measure.
```{r fit_models}
effects <- paste("age", predictors, sep = " * ")
effects_formula <- as.formula(
  glue("prop ~ (age | item) + {paste(effects, collapse = ' + ')}")
)
lex_effects <- paste("lexical_category", predictors, sep = " * ")
lex_effects_formula <- as.formula(
  glue("prop ~ (age | item) + {paste(c(effects, lex_effects), collapse = ' + ')}")
)

fit_group_model <- function(group_data, group_formula, contrasts = NULL) {
  group <- unique(group_data$group)
  message(glue("Fitting model for {group}..."))
    jglmm(formula = group_formula, data = group_data, family = "binomial",
          weights = group_data$total, contrasts = contrasts)
}

by_lang_data <- uni_model_data %>%
  mutate(group = paste(language, measure),
         lexical_category = lexical_category %>% fct_relevel("other")) %>%
  select(language, measure, group, lexical_category, item = uni_lemma, prop,
         total, age, !!predictors) %>%
  group_by(language, measure) %>%
  nest()

lang_lexcat_models <- by_lang_data %>%
  mutate(model = data %>%
           map(~fit_group_model(.x, lex_effects_formula,
                                contrasts = list(lexical_category = "effects"))))

lang_lexcat_fits <- lang_lexcat_models %>%
  mutate(results = map(model, tidy))
save(lang_lexcat_fits, file = "../saved_data/_lang_lexcat_fits.RData")
```

Spot check Julia results against lme4 results.
```{r model_comp}
eng_data <- by_lang_data %>%
  filter(language == "English (American)", measure == "understands") %>%
  pull(data) %>%
  .[[1]]

eng_model_int <- fit_group_model(eng_data, lex_effects_formula,
                                 contrasts = list(lexical_category = "effects"))
eng_effects_int <- tidy(eng_model_int)

eng_model_int_r <- glmer(
  lex_effects_formula,
  mutate(eng_data, lexical_category = lexical_category %>%
           fct_relevel("nouns", "function_words", "predicates")),
  family = "binomial", weights = eng_data$total,
  contrasts = list(lexical_category = contr.sum)
)
current <- getME(eng_model_int_r, c("theta", "fixef"))
eng_model_int_r_update <- update(eng_model_int_r, start = current)
eng_effects_int_r <- tidy(eng_model_int_r_update) %>% filter(group == "fixed")

eng_effects_int_r %>% filter(group == "fixed") %>% select(term, estimate) %>%
  bind_cols(eng_effects_int %>% select(term, estimate)) %>%
  mutate(diff = abs(estimate - estimate1)) %>% arrange(desc(diff))
```

Tidy up coefficients from models.
```{r lang_lexcat_coefs}
measure_levels <- c("understands", "produces")

lang_lexcat_coefs <- lang_lexcat_fits %>%
  select(language, measure, results) %>%
  unnest() %>%
  rename(std_error = std.error,
         z_value = z.value,
         p_value = p.value) %>%
  separate(term, c("term", "effect"), sep = " & ", fill = "right") %>%
  mutate(effect = if_else(is.na(effect), "main effect", effect),
         term = if_else(term == "age" & effect != "main effect",
                        effect, term),
         effect = if_else(term == effect, "age", effect),
         effect = if_else(effect == "main effect", effect,
                          paste("interaction with", effect)),
         effect = effect %>%
           fct_relevel("main effect",
                       "interaction with age",
                       "interaction with lexical_category: nouns",
                       "interaction with lexical_category: predicates"),
         measure = factor(measure, levels = measure_levels),
         signif = p_value < .alpha) %>%
  group_by(language, measure, term, effect) %>%
  nest()

predictor_effects <- lang_lexcat_coefs %>%
  filter(effect == "main effect", term %in% predictors) %>%
  rename(predictor_effect = data) %>%
  select(-effect)

lexcat_effects <- lang_lexcat_coefs %>%
  filter(effect == "main effect",
         str_detect(term, "lexical_category")) %>%
  mutate(lexical_category = str_match(term, ": (.*)$")[,2]) %>%
  rename(lexcat_effect = data) %>%
  select(-term, -effect)

lexcat_coefs <- lang_lexcat_coefs %>%
  filter(str_detect(effect, "lexical_category")) %>%
  mutate(lexical_category = str_match(effect, ": (.*)$")[,2]) %>%
  rename(interaction = data) %>%
  select(-effect) %>%
  left_join(predictor_effects) %>%
  left_join(lexcat_effects) %>%
  unnest(.sep = "_") %>%
  mutate(estimate = predictor_effect_estimate +
           lexcat_effect_estimate + interaction_estimate)
save(lexcat_coefs, file = "../saved_data/lexcat_coefs.RData")

lang_coefs <- lang_lexcat_coefs %>%
  filter(str_detect(effect, "main|age"), term %in% predictors) %>%
  unnest()
save(lang_coefs, file = "../saved_data/lang_coefs.RData")
```
