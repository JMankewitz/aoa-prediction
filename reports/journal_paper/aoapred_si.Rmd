---
output:
  latex_fragment:
    md_extensions: -citations-autolink_bare_uris-auto_identifiers-implicit_header_references
---

\appendix
\pagenumbering{gobble}
\renewcommand\thefigure{SI.\arabic{figure}}
\setcounter{figure}{0}

```{r si_setup, child="setup.Rmd", cache=FALSE}
```

```{r si_model_checks, child="model_checks.Rmd"}
```

# Supplemental Information {-}

In this supplemental information document, we include a variety of visualizations that provide additional information about our datasets and models. As noted in the manuscript, all of the code and data for our analyses are available at \href{https://github.com/mikabr/aoa-prediction}{github.com/mikabr/aoa-prediction}. In addition to the code for wrangling and analyzing all the data, this includes cached versions of the all the intermediate results, such as all of the coefficient estimates. We welcome extensions of our work or alternate analyses of our data -- feel free to contact the corresponding author at \href{mailto:mikabr@mit.edu}{mikabr@mit.edu} with any questions.

## Model specification

All models were fit in Julia using the MixedModels package. For a given subset of the data (e.g. data for a English production), for each CDI item (`item`), we computed the proportion of children reported to understand/produce it (`prop`) and the total number of children (`total`). We then fit a generalized linear mixed model to the data subset, with a binomial response distribution, the values in `total` as the trial weights, and the following formula:

\begin{lstlisting}
prop ~ (age | item) + age * valence + age * arousal
                    + age * num_phons + age * final_frequency
                    + age * MLU + age * solo_frequency
                    + age * concreteness + age * frequency
                    + age * babiness
\end{lstlisting}

So the regression predicts the proportion of successes (proportion of children who understand/produce each item) out of the total number of trials (number of children) from the children's age, each item-level predictor, and the interactions between age and each item-level predictor, with a random slope for age by item.

\clearpage

## Age distributions

We report the distribution of children's ages for each language and measure. This addresses the potential concern that large differences in age between samples could unbalance the design. The age distributions largely overlap, which makes sense given that many of the datasets are from normative studies that attempted to sample evenly across ages.

```{r age-dist, fig.pos='bh', fig.height=5.5, out.width="90%", fig.cap="Densities of children's ages for each language and measure, along with a label for the total numbers of children."}
measure_admins <- admins %>%
  mutate(produces = TRUE, understands = form == "WG") %>%
  select(-form) %>%
  arrange(language) %>%
  mutate(language = str_replace(language, " \\(.*\\)", ""),
         language = fct_rev(fct_inorder(language)))

sample_sizes <- bind_rows(
  measure_admins %>% filter(produces) %>% mutate(measure = "Produces"),
  measure_admins %>% filter(understands) %>% mutate(measure = "Understands")
) %>%
  mutate(measure = fct_relevel(measure, "Understands", "Produces"))

totals <- sample_sizes %>%
  group_by(measure) %>%
  mutate(max_age = max(age)) %>%
  group_by(language, measure, max_age) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(measure = fct_relevel(measure, "Understands", "Produces"))

ggplot(sample_sizes, aes(x = age, y = language)) +
  facet_wrap(~measure, scales = "free_x") +
  geom_density_ridges(aes(fill = language)) +
  geom_label(aes(label = n, x = max_age), data = totals, vjust = 0,
             hjust = "inward",
             size = 3, nudge_y = 0.05, label.size = 0.2,
             label.padding = unit(0.1, "lines"), family = .family) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(x = "Age (months)", y = "") +
  scale_fill_ptol(guide = FALSE) +
  theme(plot.title = element_text(size = rel(1.2)))
```

\clearpage

## Predictor values

As another illustration of the structure of our dataset, we show the centered and scaled distribution of the values of each predictor in each language, as well as the mean and 95% confidence interval of their raw values.

```{r predictor-dist, fig.pos='bh', fig.width=8, fig.height=8, out.width="85%", fig.cap="Densities of the scaled and centered values of each predictor for each language."}
predictor_values <- uni_model_data %>%
  ungroup() %>%
  select(language, !!predictors) %>%
  distinct() %>%
  gather(predictor, value, !!predictors) %>%
  mutate(predictor = factor(predictor, levels = rev(names(display_predictors)),
                            labels = rev(unname(display_predictors))),
         language = str_replace(language, " \\(.*\\)", ""),
         language = fct_inorder(language))

ggplot(predictor_values, aes(x = value, y = predictor, fill = predictor)) +
  facet_wrap(~language, nrow = 2) +
  geom_vline(xintercept = 0, colour = .grey, linetype = "dotted") +
  geom_density_ridges(rel_min_height = 0.01, scale = 0.95, alpha = 0.7) +
  scale_x_continuous(expand = c(0.01, 0), limits = c(-3, 3)) +
  scale_y_discrete(expand = c(0, 0),
                   limits = rev(levels(predictor_values$predictor))) +
  scale_fill_ptol(guide = FALSE) +
  labs(x = "Scaled value", y = "") +
  theme(plot.title = element_text(size = rel(1.5)))
```

```{r predictor-mean, fig.pos='bh', fig.width=9, fig.height=7, fig.cap="Means and 95\\% confidence intervals of the values of each predictor for each language."}
predictor_values <- uni_joined %>%
  select(language, uni_lemma, !!predictors) %>%
  distinct() %>%
  group_by(language) %>%
  mutate_at(vars(!!predictors), funs(as.numeric(Hmisc::impute(.)))) %>%
  ungroup() %>%
  gather(predictor, value, !!predictors) %>%
  mutate(predictor = factor(predictor, levels = rev(names(display_predictors)),
                            labels = rev(unname(display_predictors))),
         language = str_replace(language, " \\(.*\\)", ""),
         language = fct_inorder(language))

predictor_summary <- predictor_values %>%
  group_by(language, predictor) %>%
  summarise(mean = mean(value),
            se = sem(value)) %>%
  ungroup() %>%
  arrange(predictor, mean) %>%
  mutate(order = row_number())

ggplot(predictor_summary, aes(x = order, y = mean, colour = language)) +
  facet_wrap(~predictor, scales = "free") +
  coord_flip() +
  geom_crossbar(aes(ymin = mean - 1.96 * se, ymax = mean + 1.96 * se),
                width = 0.5, fatten = 0, colour = .grey) +
  geom_crossbar(aes(ymin = mean, ymax = mean),
                width = 0.75) +
  scale_x_continuous(breaks = predictor_summary$order,
                     labels = predictor_summary$language) +
  scale_colour_ptol(guide = FALSE) +
  labs(y = "Predictor value", x = "")
```

\clearpage

## Frequency and lexical category

A potential concern about our lexical category analysis is that lexical category might not be dissociable from frequency, in the sense that closed-class words are more frequent that open-class words and span a more narrower range of frequencies. The distribution of frequencies by lexical category in our dataset, shown below, demonstrates that there is substantial overlap in frequency between the closed-class and open-class words.

```{r freq-dist, fig.pos='bh', fig.width=8, fig.height=5, out.width="80%", fig.cap="Densities of the frequency estimates for open and closed class words in each language."}
freq_values <- uni_model_data %>%
  ungroup() %>%
  select(language, lexical_classes, frequency) %>%
  distinct() %>%
  filter(!str_detect(lexical_classes, ","))  %>%
  mutate(language = str_replace(language, " \\(.*\\)", ""),
         language = fct_inorder(language),
         lexical_classes = fct_other(lexical_classes, keep = "function_words"),
         lexical_classes = fct_recode(lexical_classes,
                                      "Open class" = "Other",
                                      "Closed class" = "function_words"))

ggplot(freq_values, aes(x = frequency, y = lexical_classes)) +
  facet_wrap(~language, nrow = 2) +
  geom_vline(xintercept = 0, colour = "darkgrey", linetype = "dotted") +
  geom_density_ridges(aes(fill = lexical_classes), rel_min_height = 0.01,
                      scale = 0.95, alpha = 0.7) +
  scale_x_continuous(expand = c(0.01, 0), limits = c(-3, 3)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_ptol(guide = FALSE) +
  labs(x = "Scaled frequency", y = "") +
  theme(plot.title = element_text(size = rel(1.5)))
```

\clearpage

## Pairwise predictor correlations

In addition to the univariate distribution of each predictor shown above, we show the correlation between each pair of predictors. Too many large correlations between predictors could limit the interpretability of our coefficient estimates.

```{r predictor-cors, fig.pos='bh', fig.height=8, fig.width=10, fig.cap="Pairwise correlations between predictors."}
predictor_cors %>%
  mutate(predictor1 = predictor1 %>%
           factor(levels = predictors,
                  labels = display_predictors[predictors]),
         predictor2 = predictor2 %>%
           factor(levels = rev(predictors),
                  labels = rev(display_predictors[predictors])),
         language = gsub("(.*) \\(.*\\)", "\\1", language)) %>%
ggplot(aes(x = predictor2, y = predictor1)) +
  facet_wrap(~language, ncol = 4) +
  coord_equal() +
  geom_tile(aes(fill = abs(correlation))) +
  geom_text(aes(label = map_chr(correlation, inline_hook)), size = 2.5,
            family = .family) +
  scale_fill_gradient(low = ptol_pal()(2)[[1]], high = ptol_pal()(2)[[2]],
                      breaks = c(0, 0.2, 0.4, 0.6), labels = c(0, 0.2, 0.4, 0.6),
                      limits = c(0, max(abs(predictor_cors$correlation))),
                      guide = guide_colourbar(title.position = "top",
                                              title.hjust = 0.5,
                                              barwidth = 10,
                                              frame.colour = .grey)) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(x = "", y = "", fill = "Correlation magnitude") +
  theme(legend.position = c(0.8, 0),
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 30, hjust = 1),
        plot.title = element_text(size = rel(1.8)))
```

\clearpage

## Variance inflation factors

To address the potential issue of multicollinearity in our models, we show the variance inflation factor (VIF) for each predictor in each language. VIF is computed for a predictor by fitting an ordinary least squares regression with that predictor as the dependent variable and all other predictors as the independent variables, getting its $R^2$, and then computing $\text{VIF} = \frac{1}{1 - R^2}$.

```{r vifs, fig.pos='bh', fig.height=5.5, out.width="70%", fig.cap="Variance inflation factors of the predictors."}
vifs %>%
  mutate(predictor = predictor %>%
           factor(levels = predictors,
                  labels = display_predictors[predictors]),
         language = gsub("(.*) \\(.*\\)", "\\1", language)) %>%
ggplot(aes(x = language, y = predictor)) +
  coord_equal() +
  geom_tile(aes(fill = vif)) +
  geom_text(aes(label = round(vif, 2)), size = 3, family = .family) +
  scale_fill_gradient(low = ptol_pal()(2)[[1]], high = ptol_pal()(2)[[2]],
                      breaks = c(1, 1.5, 2, 2.5), limits = c(1, 2.5)) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(x = "", y = "", fill = "VIF") +
  theme(legend.position = "top",
        legend.title = element_text(vjust = 0.8),
        axis.text.x = element_text(angle = 30, hjust = 1),
        plot.title = element_text(size = rel(1.2)))
```

\clearpage

## Coefficients by language

As a supplement to Figure \ref{fig:langcoefs}, we show the coefficient estimates separately for each language.

```{r by-lang-coefs, fig.pos='bh!', fig.height=10, fig.width=10, fig.cap="Coeffiecients for each language with 95\\% confidence intervals."}
by_lang_plot <- function(meas) {
  ggplot(filter(plt_lang_coefs, measure == meas,
                interaction == "main effect"),
         aes(x = estimate, y = term)) +
    facet_wrap(~language, nrow = 2) +
    geom_pointrangeh(aes(colour = term, shape = fct_rev(signif),
                         xmin = estimate - 1.96 * std_error,
                         xmax = estimate + 1.96 * std_error)) +
    geom_vline(xintercept = 0, color = .grey, linetype = "dotted") +
    scale_colour_ptol(guide = FALSE) +
    scale_shape_manual(values = c(19, 21), guide = FALSE) +
    labs(y = "", x = "Coefficient estimate") #+
    #theme(plot.margin = margin(t = 16, unit = "pt"))
}

plot_grid(by_lang_plot("understands"), by_lang_plot("produces"), ncol = 1,
          labels = c("Understands", "Produces"), label_size = 16, hjust = 0)
```

\clearpage

## Coefficients by measure

Also as a supplement to Figure \ref{fig:langcoefs}, we show the coefficient estimates separately for each language, this time paired by comprehension and production.

```{r prod-comp-coefs, fig.pos='bh', fig.width=10, fig.height=6.5, fig.cap="Paired coefficients for comprehension and production."}
ggplot(filter(plt_lang_coefs, interaction == "main effect"),
       aes(x = estimate, y = term, colour = measure, shape = measure)) +
  facet_wrap(~language, ncol = 5) +
  geom_point() +
  geom_vline(xintercept = 0, color = "grey", linetype = "dotted") +
  scale_colour_ptol() +
  labs(y = "", x = "Coefficient estimate", colour = "", shape = "") +
  theme(legend.position = "top",
        plot.title = element_text(size = rel(1.8)))
```

\clearpage

## Consistency by lexical category

As a supplement to Figure \ref{fig:consistency}, we show the correlations of coefficient estimates between languages separately for each lexical category.

```{r lexcat-consistency, fig.pos='bh', fig.width=7, fig.asp=1, out.width="80%", fig.cap="Consistency of coefficients within each lexical category."}
lexcat_coef_summary_means <- lexcat_coef_summary %>%
  group_by(lexical_category, measure) %>%
  summarise(mean_cor = mean(mean_cor))

ggplot(lexcat_coef_summary, aes(x = mean_cor, y = language)) +
  facet_grid(lexical_category ~ measure, labeller = as_labeller(label_caps)) +
  geom_vline(aes(xintercept = mean_cor), colour = "grey70", size = 0.4,
             data = lexcat_coef_summary_means) +
  geom_point(aes(colour = language), size = 2) +
  geom_rect(aes(xmin = ci_lower_cor, xmax = ci_upper_cor,
                ymin = as.numeric(language) + 0.4,
                ymax = as.numeric(language) - 0.4,
                fill = language),
            data = lexcat_baseline_coef_summary,
            alpha = .2, linetype = 0) +
  geom_segment(aes(x = mean_cor, xend = mean_cor,
                   y = as.numeric(language) + 0.4,
                   yend = as.numeric(language) - 0.4),
               data = lexcat_baseline_coef_summary,
               colour = "grey70") +
  scale_x_continuous(breaks = seq(-0.2, 1, 0.2)) +
  labs(x = "Mean correlation with other languages' coefficients", y = "") +
  scale_colour_ptol(guide = FALSE) +
  scale_fill_ptol(guide = FALSE)
```

```{r transcripts, include=FALSE}
library(childesr)

languages <- unique(lang_coefs$language) %>% str_remove(" (.*)")
iso_codes <- as_tibble(ISOcodes::ISO_639_3) %>%
  select(language = Name, code = Id)

transcripts <- get_transcripts()
transcripts %>%
  rename(code = language) %>%
  left_join(iso_codes) %>%
  select(language, corpus_id, transcript_id) %>%
  filter(language %in% languages) %>%
  group_by(language) %>%
  summarise(num_corpora = n_distinct(corpus_id),
            num_transcripts = n_distinct(transcript_id)) %>%
  arrange(desc(num_transcripts))
```
